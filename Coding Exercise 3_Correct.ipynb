{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Start by setting up your content import. You can use the same target content as you used for exercise two, or set up something new. Read in and store the content from a single URL.\r\n",
    "\r\n",
    "import urllib.request, urllib.error, urllib.parse\r\n",
    "\r\n",
    "url = 'https://www.rottentomatoes.com/m/full_metal_jacket/reviews?intcmp=rt-scorecard_tomatometer-revie'\r\n",
    "\r\n",
    "response = urllib.request.urlopen(url)\r\n",
    "webContents = response.read()\r\n",
    "\r\n",
    "print(webContents[0:1000])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\"\\n      dir=\"ltr\"\\n      xmlns:fb=\"http://www.facebook.com/2008/fbml\"\\n      xmlns:og=\"http://opengraphprotocol.org/schema/\">\\n\\n    <head prefix=\"og: http://ogp.me/ns# flixstertomatoes: http://ogp.me/ns/apps/flixstertomatoes#\">\\n        \\n            <script src=\"/assets/pizza-pie/javascripts/bundles/roma/rt-common.js?single\"></script>\\n        \\n        <!-- salt=lay-def-02-juRm -->\\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\\n        <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\n        <title>Full Metal Jacket - Movie Reviews</title>\\n        <meta name=\"description\" content=\"Rotten Tomatoes, home of the Tomatometer, is the most trusted measurement of quality for Movies & TV. The definitive site for Reviews, Trailers, Showtimes, and Tickets\">\\n\\n        \\n            <link rel=\"canonical\" href=\"https://www.rottentomatoes.com/m/full_metal_jacket\">\\n'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Next, splice the content you've imported to include only the primary text of interest. You'll need to investigate the website you are looking at and choose strategically what tags you look for to define the starting and ending location of your splice. Build on the model in CleaningHTML.ipynb\r\n",
    "\r\n",
    "contents = str(webContents)\r\n",
    "# The start of the review section\r\n",
    "startLoc = contents.find(\"<a href=\\\"/critic/andrew-pollard\")\r\n",
    "# The end of the review section\r\n",
    "endLoc = contents.find(\"harsh and explicit.\")\r\n",
    "\r\n",
    "print(startLoc)\r\n",
    "print(endLoc)\r\n",
    "\r\n",
    "contents = contents[startLoc: endLoc]\r\n",
    "print(contents[0: 500])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "148588\n",
      "189829\n",
      "<a href=\"/critic/andrew-pollard\" class=\"unstyled bold articleLink\" data-qa=\"review-critic-link\">Andrew Pollard</a>\\r\\n                \\r\\n            \\r\\n            <br/>\\r\\n            \\r\\n                <a href=\"/source-2424\">\\r\\n                    <em class=\"subtle critic-publication\" data-qa=\"review-critic-publication\">Starburst</em>\\r\\n                </a>\\r\\n            \\r\\n            \\r\\n        </div>\\r\\n    </div>\\r\\n    <div class=\"col-xs-16 review_container\">\\r\\n        \\r\\n      \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "\r\n",
    "# Implement a loop to remove all the HTML tags from your text. Use the model provided in CleaningHTML.ipynb, and make sure to store your cleaned text as a string. Print the string and inspect the results. Save your now  cleaned text as a .txt file with an appropriate name.\r\n",
    "\r\n",
    "inside = 0\r\n",
    "text = ''\r\n",
    "\r\n",
    "for char in contents:\r\n",
    "    if char == '<':\r\n",
    "        inside = 1\r\n",
    "    elif (inside == 1 and char == '>'):\r\n",
    "        inside = 0\r\n",
    "    elif inside== 1:\r\n",
    "        continue\r\n",
    "    else: \r\n",
    "        text += char\r\n",
    "\r\n",
    "text = text.replace(\"\\\\n\",\"\")\r\n",
    "text = text.replace(\"\\\\r\",\"\")\r\n",
    "print(text[0: 500])\r\n",
    "\r\n",
    "f = open('FMJ_Reviews_Clean.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Andrew Pollard                                                                                        Starburst                                                                                                                                                    Sep 24, 2020                                                            A hard-hitting movie laced with moments of dark humour and brimming with social commentary, Full Metal Jacket is viewed as one of the all-time great war movie.          \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Now we're ready to analyze our text. This time, try combining the elements we've used so far to handle our text by writing a simple algorithm following this model:\r\n",
    "\r\n",
    "# First, split your string into a \"bag of words\" by cutting at the whitespace into an array.\r\n",
    "text = text.lower()\r\n",
    "wordBag = text.split()\r\n",
    "\r\n",
    "# Next, create a loop that runs through every word in your new array\r\n",
    "# Within the loop, create some conditionals and behaviors to process the words. For instance, you might print out every word that starts with a certain letter, or print out words longer than a set length, etc. Try playing with the loop breaks and continue options to handle different types of words differently.\r\n",
    "\r\n",
    "for word in wordBag:\r\n",
    "    if word == \"Joker\":\r\n",
    "        print(\"The reviewer mentioned the character named Joker.\")\r\n",
    "    elif word == \"dark\" or word == \"humor\" or word == \"humour\":\r\n",
    "        print(\"The reviewer has acknowledged \" + word)\r\n",
    "    #note if punctuation is adjacent to word (ie: dark.) the word will not appear here.  Week for helps correct this.\r\n",
    "    elif len(word) > 10:\r\n",
    "        print(word)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hard-hitting\n",
      "The reviewer has acknowledged dark\n",
      "The reviewer has acknowledged humour\n",
      "commentary,\n",
      "flickdirect\n",
      "theindependentcritic.com\n",
      "performance.\n",
      "contrasting\n",
      "soundtrack,\n",
      "mesmerizing\n",
      "photography,\n",
      "indoctrination\n",
      "fundamental\n",
      "electrifying\n",
      "self-pleasing\n",
      "international\n",
      "[kubrick\\'s]\n",
      "terrifyingly\n",
      "justifiably\n",
      "challenging\n",
      "uncomfortable\n",
      "machine-like\n",
      "extraordinary.\n",
      "philadelphia\n",
      "philadelphia\n",
      "considerable\n",
      "achievement\n",
      "satisfaction.\n",
      "relentlessly\n",
      "nonetheless\n",
      "sun-sentinel\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "384b16392d5df87b45fa68fd804fdd570b449e149e441c1270eb35604a8982f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}