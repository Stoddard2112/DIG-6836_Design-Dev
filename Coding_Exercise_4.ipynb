{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "print (\"Let's start coding...)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Let's start coding...)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print (\"Now I shall begin Coding Exercise 4!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Now I shall begin Coding Exercise 4!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# For this exercise, you should start by reading in the text file produced from Exercise Three. This text file should already have the HTML code elements removed, and primarily consist of text and other characters that we will remove through our processing. Store the input of your file in a string, and convert the contents to lower case for consistency.\r\n",
    "\r\n",
    "f = open('FMJ_Reviews_Clean.txt', 'r')\r\n",
    "text = f.read()\r\n",
    "f.close()\r\n",
    "\r\n",
    "word_bag = text.split()\r\n",
    "print(word_bag[0:100])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Andrew', 'Pollard', 'Starburst', 'Sep', '24,', '2020', 'A', 'hard-hitting', 'movie', 'laced', 'with', 'moments', 'of', 'dark', 'humour', 'and', 'brimming', 'with', 'social', 'commentary,', 'Full', 'Metal', 'Jacket', 'is', 'viewed', 'as', 'one', 'of', 'the', 'all-time', 'great', 'war', 'movie.', 'Full', 'Review', '|', 'Original', 'Score:', '5/5', 'Allison', 'Rose', 'FlickDirect', 'Sep', '22,', '2020', 'Kubrick', 'had', 'a', 'way', 'of', 'making', 'the', 'audience', 'become', 'invested', 'in', 'the', 'characters', 'of', 'his', 'films', 'and', 'created', 'some', 'truly', 'memorable', 'ones.', 'Full', 'Review', '|', 'Original', 'Score:', '4.5/5', 'Richard', 'Propes', 'TheIndependentCritic.com', 'Sep', '8,', '2020', 'It', 'was', 'a', 'gross', 'injustice', 'that', 'Ermey', 'was', 'not', 'nominated', 'for', 'his', 'tremendous', 'performance.', 'Full', 'Review', '|', 'Original', 'Score:', '3.5/4.0', 'Mike']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Conversion to lower case.\r\n",
    "text = text.lower()\r\n",
    "word_bag = text.split()\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['andrew', 'pollard', 'starburst', 'sep', '24,', '2020', 'a', 'hard-hitting', 'movie', 'laced', 'with', 'moments', 'of', 'dark', 'humour', 'and', 'brimming', 'with', 'social', 'commentary,', 'full', 'metal', 'jacket', 'is', 'viewed', 'as', 'one', 'of', 'the', 'all-time', 'great', 'war', 'movie.', 'full', 'review', '|', 'original', 'score:', '5/5', 'allison', 'rose', 'flickdirect', 'sep', '22,', '2020', 'kubrick', 'had', 'a', 'way', 'of', 'making', 'the', 'audience', 'become', 'invested', 'in', 'the', 'characters', 'of', 'his', 'films', 'and', 'created', 'some', 'truly', 'memorable', 'ones.', 'full', 'review', '|', 'original', 'score:', '4.5/5', 'richard', 'propes', 'theindependentcritic.com', 'sep', '8,', '2020', 'it', 'was', 'a', 'gross', 'injustice', 'that', 'ermey', 'was', 'not', 'nominated', 'for', 'his', 'tremendous', 'performance.', 'full', 'review', '|', 'original', 'score:', '3.5/4.0', 'mike']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Storing new lowercase txt file of reviews.\r\n",
    "f = open('FMJ_Reviews_Clean_Lower.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# This week, we'll be using functions that we've already defined in our exercises. Try looking back through your code and notes from class. Our first step is to import the regular expressions module and remove all non-alpha-numeric characters from the string, then save the string as an array of words ready for processing. (Use the code in NormalizingText for reference)\r\n",
    "\r\n",
    "#Opening new lowerscase version of reviews.\r\n",
    "f = open('FMJ_Reviews_Clean_Lower.txt', 'r')\r\n",
    "text = f.read()\r\n",
    "f.close()\r\n",
    "\r\n",
    "wtext = text.lower()\r\n",
    "# RE = regualr expressions. Importing the library of re.  They are how we understadn the relations of text.  Using this here to only retunr alphanumeric characters in our txt file. Notice, it did not get rid of all the problem content (r's and n's).\r\n",
    "import re\r\n",
    "word_bag = re.compile(r'\\W+', re.UNICODE).split(text)\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['andrew', 'pollard', 'starburst', 'sep', '24', '2020', 'a', 'hard', 'hitting', 'movie', 'laced', 'with', 'moments', 'of', 'dark', 'humour', 'and', 'brimming', 'with', 'social', 'commentary', 'full', 'metal', 'jacket', 'is', 'viewed', 'as', 'one', 'of', 'the', 'all', 'time', 'great', 'war', 'movie', 'full', 'review', 'original', 'score', '5', '5', 'allison', 'rose', 'flickdirect', 'sep', '22', '2020', 'kubrick', 'had', 'a', 'way', 'of', 'making', 'the', 'audience', 'become', 'invested', 'in', 'the', 'characters', 'of', 'his', 'films', 'and', 'created', 'some', 'truly', 'memorable', 'ones', 'full', 'review', 'original', 'score', '4', '5', '5', 'richard', 'propes', 'theindependentcritic', 'com', 'sep', '8', '2020', 'it', 'was', 'a', 'gross', 'injustice', 'that', 'ermey', 'was', 'not', 'nominated', 'for', 'his', 'tremendous', 'performance', 'full', 'review', 'original']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Next, we'll use stop words to remove all the words that we don't want to include in our count. There are suggested words in this week's readings, but you can also generate a custom list based on your topic. Define the stop words in an array, and use a loop to remove any word in your bag of words that also appears on the stop words list (use the examples in Dictionaries for guidance.)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Now we're ready to count our words, and move from an array to a dictionary. Using the functions we've already built in the \"Dictionaries.ipynb\" file, process your text by building a dictionary that zips words with their frequency, then removes redundancy by storing the data in the \"dictionary\" format."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finally, explore what you can learn from this dictionary. Try: \r\n",
    "# A. Sorting your dictionary using our prebuilt method\r\n",
    "# B. Printing the top five most frequent words from your data\r\n",
    "# C. Querying for certain key words and printing their frequency\r\n",
    "# D. Comparing the relative frequency of words of interest"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "384b16392d5df87b45fa68fd804fdd570b449e149e441c1270eb35604a8982f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}