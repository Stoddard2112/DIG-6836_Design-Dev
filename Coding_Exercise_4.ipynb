{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "print (\"Let's start coding...)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Let's start coding...)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print (\"Now I shall begin Coding Exercise 4!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Now I shall begin Coding Exercise 4!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# For this exercise, you should start by reading in the text file produced from Exercise Three. This text file should already have the HTML code elements removed, and primarily consist of text and other characters that we will remove through our processing. Store the input of your file in a string, and convert the contents to lower case for consistency.\r\n",
    "\r\n",
    "f = open('FMJ_Reviews_Clean.txt', 'r')\r\n",
    "text = f.read()\r\n",
    "f.close()\r\n",
    "\r\n",
    "word_bag = text.split()\r\n",
    "print(word_bag[0:100])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Andrew', 'Pollard', 'Starburst', 'Sep', '24,', '2020', 'A', 'hard-hitting', 'movie', 'laced', 'with', 'moments', 'of', 'dark', 'humour', 'and', 'brimming', 'with', 'social', 'commentary,', 'Full', 'Metal', 'Jacket', 'is', 'viewed', 'as', 'one', 'of', 'the', 'all-time', 'great', 'war', 'movie.', 'Full', 'Review', '|', 'Original', 'Score:', '5/5', 'Allison', 'Rose', 'FlickDirect', 'Sep', '22,', '2020', 'Kubrick', 'had', 'a', 'way', 'of', 'making', 'the', 'audience', 'become', 'invested', 'in', 'the', 'characters', 'of', 'his', 'films', 'and', 'created', 'some', 'truly', 'memorable', 'ones.', 'Full', 'Review', '|', 'Original', 'Score:', '4.5/5', 'Richard', 'Propes', 'TheIndependentCritic.com', 'Sep', '8,', '2020', 'It', 'was', 'a', 'gross', 'injustice', 'that', 'Ermey', 'was', 'not', 'nominated', 'for', 'his', 'tremendous', 'performance.', 'Full', 'Review', '|', 'Original', 'Score:', '3.5/4.0', 'Mike']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Conversion to lower case.\r\n",
    "text = text.lower()\r\n",
    "word_bag = text.split()\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['andrew', 'pollard', 'starburst', 'sep', '24,', '2020', 'a', 'hard-hitting', 'movie', 'laced', 'with', 'moments', 'of', 'dark', 'humour', 'and', 'brimming', 'with', 'social', 'commentary,', 'full', 'metal', 'jacket', 'is', 'viewed', 'as', 'one', 'of', 'the', 'all-time', 'great', 'war', 'movie.', 'full', 'review', '|', 'original', 'score:', '5/5', 'allison', 'rose', 'flickdirect', 'sep', '22,', '2020', 'kubrick', 'had', 'a', 'way', 'of', 'making', 'the', 'audience', 'become', 'invested', 'in', 'the', 'characters', 'of', 'his', 'films', 'and', 'created', 'some', 'truly', 'memorable', 'ones.', 'full', 'review', '|', 'original', 'score:', '4.5/5', 'richard', 'propes', 'theindependentcritic.com', 'sep', '8,', '2020', 'it', 'was', 'a', 'gross', 'injustice', 'that', 'ermey', 'was', 'not', 'nominated', 'for', 'his', 'tremendous', 'performance.', 'full', 'review', '|', 'original', 'score:', '3.5/4.0', 'mike']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Storing new lowercase txt file of reviews.\r\n",
    "f = open('FMJ_Reviews_Clean_Lower.txt','w')\r\n",
    "f.write(text)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# This week, we'll be using functions that we've already defined in our exercises. Try looking back through your code and notes from class. Our first step is to import the regular expressions module and remove all non-alpha-numeric characters from the string, then save the string as an array of words ready for processing. (Use the code in NormalizingText for reference)\r\n",
    "\r\n",
    "#Opening new lowerscase version of reviews.\r\n",
    "f = open('FMJ_Reviews_Clean_Lower.txt', 'r')\r\n",
    "text = f.read()\r\n",
    "f.close()\r\n",
    "\r\n",
    "wtext = text.lower()\r\n",
    "# RE = regualr expressions. Importing the library of re.  They are how we understadn the relations of text.  Using this here to only retunr alphanumeric characters in our txt file. Notice, it did not get rid of all the problem content (r's and n's).\r\n",
    "import re\r\n",
    "word_bag = re.compile(r'\\W+', re.UNICODE).split(text)\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['andrew', 'pollard', 'starburst', 'sep', '24', '2020', 'a', 'hard', 'hitting', 'movie', 'laced', 'with', 'moments', 'of', 'dark', 'humour', 'and', 'brimming', 'with', 'social', 'commentary', 'full', 'metal', 'jacket', 'is', 'viewed', 'as', 'one', 'of', 'the', 'all', 'time', 'great', 'war', 'movie', 'full', 'review', 'original', 'score', '5', '5', 'allison', 'rose', 'flickdirect', 'sep', '22', '2020', 'kubrick', 'had', 'a', 'way', 'of', 'making', 'the', 'audience', 'become', 'invested', 'in', 'the', 'characters', 'of', 'his', 'films', 'and', 'created', 'some', 'truly', 'memorable', 'ones', 'full', 'review', 'original', 'score', '4', '5', '5', 'richard', 'propes', 'theindependentcritic', 'com', 'sep', '8', '2020', 'it', 'was', 'a', 'gross', 'injustice', 'that', 'ermey', 'was', 'not', 'nominated', 'for', 'his', 'tremendous', 'performance', 'full', 'review', 'original']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Next, we'll use stop words to remove all the words that we don't want to include in our count. There are suggested words in this week's readings, but you can also generate a custom list based on your topic. Define the stop words in an array, and use a loop to remove any word in your bag of words that also appears on the stop words list (use the examples in Dictionaries for guidance.)\r\n",
    "\r\n",
    "# sets up a stops words function as an array.\r\n",
    "stopwords = ['a','n','the','my', 'with', 'of', 'and', 'is', 'as']\r\n",
    "stopwords += ['i', 'that', 'was', 'it', 'for', 'this']\r\n",
    "stopwords += ['s', 'on', 'to', 'an', 'but', 'from', 'in', 'us', 'all']\r\n",
    "# Applies stop words to bag of words and only returns unstopped words.\r\n",
    "def removeStopWords(word_bag, stopwords):\r\n",
    "    return [w for w in word_bag if w not in stopwords]\r\n",
    "# Below is the test of the fucntion, can replace with my own dataset.\r\n",
    "stoped_word_bag = removeStopWords(word_bag, stopwords)\r\n",
    "# counted_words = wordsToDictionary(word_bag)\r\n",
    "# ounted_words = sortDictionary(counted_words)\r\n",
    "print(stoped_word_bag[0:100])\r\n",
    "# Now we can see whats really in our text."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['andrew', 'pollard', 'starburst', 'sep', '24', '2020', 'hard', 'hitting', 'movie', 'laced', 'moments', 'dark', 'humour', 'brimming', 'social', 'commentary', 'full', 'metal', 'jacket', 'viewed', 'one', 'time', 'great', 'war', 'movie', 'full', 'review', 'original', 'score', '5', '5', 'allison', 'rose', 'flickdirect', 'sep', '22', '2020', 'kubrick', 'had', 'way', 'making', 'audience', 'become', 'invested', 'characters', 'his', 'films', 'created', 'some', 'truly', 'memorable', 'ones', 'full', 'review', 'original', 'score', '4', '5', '5', 'richard', 'propes', 'theindependentcritic', 'com', 'sep', '8', '2020', 'gross', 'injustice', 'ermey', 'not', 'nominated', 'his', 'tremendous', 'performance', 'full', 'review', 'original', 'score', '3', '5', '4', '0', 'mike', 'massie', 'gone', 'twins', 'sep', '6', '2020', 'nicely', 'contrasting', 'soundtrack', 'intense', 'action', 'sequences', 'mesmerizing', 'sets', 'excellent', 'photography', 'believable']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Now we're ready to count our words, and move from an array to a dictionary. Using the functions we've already built in the \"Dictionaries.ipynb\" file, process your text by building a dictionary that zips words with their frequency, then removes redundancy by storing the data in the \"dictionary\" format.\r\n",
    "\r\n",
    "# This function takes word bag as input\r\n",
    "def wordsToDictionary(stoped_word_bag):\r\n",
    "    # Starts by counting our words, like in Counting Words ex. But shorthand.\r\n",
    "    word_freq = [stoped_word_bag.count(word) for word in stoped_word_bag]\r\n",
    "    # Returns word count to a dictionary, zips them together. Dictioanry needs a key and a value.  Makes the pairs actionable keys and values.\r\n",
    "    return dict(list(zip(stoped_word_bag,word_freq)))\r\n",
    "\r\n",
    "# Once dictionary is in place, we can print some words.\r\n",
    "test_words = [\"my\",\"words\",\"my\",\"words\",\"no\",\"word\",\"word\",\"word\"]\r\n",
    "counted_words = wordsToDictionary(stoped_word_bag)\r\n",
    "print(counted_words)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'andrew': 1, 'pollard': 1, 'starburst': 1, 'sep': 4, '24': 2, '2020': 5, 'hard': 1, 'hitting': 1, 'movie': 3, 'laced': 1, 'moments': 2, 'dark': 1, 'humour': 1, 'brimming': 1, 'social': 1, 'commentary': 1, 'full': 25, 'metal': 7, 'jacket': 7, 'viewed': 1, 'one': 5, 'time': 1, 'great': 3, 'war': 8, 'review': 18, 'original': 10, 'score': 10, '5': 11, 'allison': 1, 'rose': 1, 'flickdirect': 1, '22': 1, 'kubrick': 11, 'had': 1, 'way': 1, 'making': 2, 'audience': 1, 'become': 1, 'invested': 1, 'characters': 2, 'his': 8, 'films': 2, 'created': 1, 'some': 4, 'truly': 1, 'memorable': 1, 'ones': 1, '4': 5, 'richard': 1, 'propes': 1, 'theindependentcritic': 1, 'com': 2, '8': 2, 'gross': 1, 'injustice': 1, 'ermey': 1, 'not': 4, 'nominated': 1, 'tremendous': 1, 'performance': 1, '3': 3, '0': 1, 'mike': 1, 'massie': 1, 'gone': 1, 'twins': 1, '6': 2, 'nicely': 1, 'contrasting': 1, 'soundtrack': 1, 'intense': 1, 'action': 1, 'sequences': 1, 'mesmerizing': 1, 'sets': 1, 'excellent': 1, 'photography': 1, 'believable': 1, 'contribute': 1, 'poignant': 1, 'thriller': 1, '10': 3, 'ed': 1, 'travis': 1, 'hollywood': 1, 'jesus': 1, 'mar': 1, '31': 1, 'master': 1, 'study': 1, 'indoctrination': 1, 'fundamental': 1, 'identity': 1, 'shifts': 1, 'every': 1, 'moment': 1, 'film': 8, 'builds': 2, 'ideas': 1, 'hilary': 1, 'mantel': 1, 'spectator': 1, 'apr': 1, '9': 4, '2019': 2, 'we': 3, 'look': 1, 'director': 1, 'judgment': 1, 'or': 2, 'even': 2, 'indication': 1, 'opinion': 1, 'whether': 1, 'carnage': 1, 'artists': 1, 'are': 2, 'born': 1, 'made': 2, 'don': 1, 't': 3, 'get': 1, 'jack': 1, 'garner': 1, 'gannett': 1, 'news': 2, 'service': 1, 'feb': 1, 'electrifying': 1, 'opening': 1, 'segment': 1, 'could': 1, 'stand': 1, 'alone': 1, 'except': 1, 'only': 1, 'about': 4, '45': 1, 'minutes': 1, 'long': 2, '2': 1, 'stanley': 2, 'kauffmann': 1, 'new': 1, 'republic': 1, 'nov': 1, '2017': 1, 'seems': 1, 'further': 1, 'proof': 1, 'still': 1, 'trapped': 1, 'self': 1, 'pleasing': 1, 'cinematic': 1, 'exercise': 1, 'cathy': 1, 'burke': 1, 'united': 1, 'press': 1, 'international': 1, 'oct': 2, '2016': 1, 'produced': 1, 'directed': 1, 'co': 1, 'written': 1, 'by': 1, 'easy': 1, 'watch': 1, 'first': 1, 'frame': 1, 'last': 1, 'riveting': 1, 'john': 1, 'rico': 1, '25': 1, '2015': 3, 'classics': 1, 'cinema': 1, 'nearly': 1, 'good': 2, 'its': 5, 'legend': 1, 'suggests': 1, 'pretty': 1, '1': 1, 'peter': 1, 'travers': 1, 'people': 2, 'magazine': 1, 'jun': 8, 'genius': 1, 'perhaps': 1, 'burden': 1, 'see': 1, 'insanity': 1, 'make': 1, 'seem': 2, 'so': 1, 'terrifyingly': 1, 'normal': 1, 'david': 2, 'nusair': 1, 'reel': 1, 'reviews': 1, 'jan': 1, 'justifiably': 1, 'iconic': 1, 'tim': 1, 'brayton': 1, 'antagony': 1, 'amp': 1, 'ecstasy': 1, 'jul': 1, '2014': 1, 'foremost': 1, 'triumphs': 1, 'genuinely': 1, 'challenging': 1, 'uncomfortable': 1, 'terrence': 1, 'rafferty': 1, 'nation': 1, '21': 7, '2013': 7, 'no': 1, 'amount': 1, 'stylistic': 1, 'analysis': 1, 'however': 2, 'likely': 1, 'explain': 1, 'why': 1, 'man': 1, 'would': 1, 'devote': 1, 'more': 1, 'than': 1, 'three': 1, 'years': 1, 'life': 1, 'which': 1, 'violent': 1, 'death': 1, 'isn': 1, 'meant': 1, 'move': 1, 'does': 1, 'really': 1, 'think': 1, 're': 1, 'callous': 1, 'enough': 1, 'adrian': 1, 'turner': 1, 'radio': 1, 'times': 2, 'while': 1, 'message': 1, 'simple': 1, 'innocent': 1, 'young': 1, 'americans': 1, 'taught': 1, 'be': 2, 'machine': 1, 'like': 1, 'killers': 1, 'technique': 1, 'extraordinary': 1, 'ben': 1, 'yagoda': 1, 'philadelphia': 2, 'daily': 1, 'if': 2, 'doesn': 1, 'give': 2, 'has': 3, 'offer': 1, 'substitute': 1, 'idea': 1, 'style': 1, 'vision': 1, 'comes': 1, 'up': 2, 'blank': 1, 'desmond': 1, 'ryan': 1, 'inquirer': 1, 'considerable': 1, 'achievement': 1, 'awaited': 1, 'falls': 1, 'short': 1, 'olympian': 1, 'standards': 1, 'there': 1, 'reason': 1, 'ought': 1, 'satisfaction': 1, 'world': 1, 'caught': 1, 'what': 1, 'he': 1, 'say': 1, 'sterritt': 1, 'christian': 1, 'science': 1, 'monitor': 1, 'relentlessly': 1, 'harsh': 1, 'images': 1, 'language': 1, 'nonetheless': 1, 'most': 1, 'artful': 1, 'yet': 1, 'vietnam': 1, 'sheila': 1, 'benson': 1, 'los': 1, 'angeles': 1, 'may': 1, 'too': 3, 'spare': 1, 'clinical': 1, 'familiar': 1, 'aiming': 1, 'minds': 1, 'well': 1, 'hearts': 1, 'hits': 1, 'target': 1, 'squarely': 1, 'roger': 1, 'hurlburt': 1, 'south': 1, 'florida': 1, 'sun': 1, 'sentinel': 1, 'motion': 1, 'picture': 1, 'warned': 1, '': 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# This should sort the above unsorted dictioanry into order of most common word to least common word.\r\n",
    "# Utility func to creat a sorted version of our dictionary, sorted pattern.\r\n",
    "def sortDictionary(counted_words):\r\n",
    "    # Store new list to go through and trakc word counts to sort by count and reverse so we have counted words in order.  So we can see most common words to least common word.  Orders to fq, not to word.\r\n",
    "    aux = [(counted_words[key], key) for key in counted_words]\r\n",
    "    aux.sort()\r\n",
    "    aux.reverse()\r\n",
    "    return aux\r\n",
    "\r\n",
    "counted_words = sortDictionary(counted_words)\r\n",
    "print(counted_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(25, 'full'), (18, 'review'), (11, 'kubrick'), (11, '5'), (10, 'score'), (10, 'original'), (8, 'war'), (8, 'jun'), (8, 'his'), (8, 'film'), (7, 'metal'), (7, 'jacket'), (7, '21'), (7, '2013'), (5, 'one'), (5, 'its'), (5, '4'), (5, '2020'), (4, 'some'), (4, 'sep'), (4, 'not'), (4, 'about'), (4, '9'), (3, 'we'), (3, 'too'), (3, 't'), (3, 'movie'), (3, 'has'), (3, 'great'), (3, '3'), (3, '2015'), (3, '10'), (2, 'up'), (2, 'times'), (2, 'stanley'), (2, 'seem'), (2, 'philadelphia'), (2, 'people'), (2, 'or'), (2, 'oct'), (2, 'news'), (2, 'moments'), (2, 'making'), (2, 'made'), (2, 'long'), (2, 'if'), (2, 'however'), (2, 'good'), (2, 'give'), (2, 'films'), (2, 'even'), (2, 'david'), (2, 'com'), (2, 'characters'), (2, 'builds'), (2, 'be'), (2, 'are'), (2, '8'), (2, '6'), (2, '24'), (2, '2019'), (1, 'young'), (1, 'yet'), (1, 'years'), (1, 'yagoda'), (1, 'written'), (1, 'would'), (1, 'world'), (1, 'why'), (1, 'while'), (1, 'which'), (1, 'whether'), (1, 'what'), (1, 'well'), (1, 'way'), (1, 'watch'), (1, 'warned'), (1, 'vision'), (1, 'violent'), (1, 'viewed'), (1, 'vietnam'), (1, 'united'), (1, 'uncomfortable'), (1, 'twins'), (1, 'turner'), (1, 'truly'), (1, 'triumphs'), (1, 'tremendous'), (1, 'travis'), (1, 'travers'), (1, 'trapped'), (1, 'time'), (1, 'tim'), (1, 'thriller'), (1, 'three'), (1, 'think'), (1, 'there'), (1, 'theindependentcritic'), (1, 'than'), (1, 'terrifyingly'), (1, 'terrence'), (1, 'technique'), (1, 'taught'), (1, 'target'), (1, 'sun'), (1, 'suggests'), (1, 'substitute'), (1, 'stylistic'), (1, 'style'), (1, 'study'), (1, 'still'), (1, 'sterritt'), (1, 'starburst'), (1, 'standards'), (1, 'stand'), (1, 'squarely'), (1, 'spectator'), (1, 'spare'), (1, 'south'), (1, 'soundtrack'), (1, 'social'), (1, 'so'), (1, 'simple'), (1, 'short'), (1, 'shifts'), (1, 'sheila'), (1, 'sets'), (1, 'service'), (1, 'sequences'), (1, 'sentinel'), (1, 'self'), (1, 'segment'), (1, 'seems'), (1, 'see'), (1, 'science'), (1, 'say'), (1, 'satisfaction'), (1, 'ryan'), (1, 'rose'), (1, 'roger'), (1, 'riveting'), (1, 'rico'), (1, 'richard'), (1, 'reviews'), (1, 'republic'), (1, 'relentlessly'), (1, 'reel'), (1, 'reason'), (1, 'really'), (1, 're'), (1, 'rafferty'), (1, 'radio'), (1, 'propes'), (1, 'proof'), (1, 'produced'), (1, 'pretty'), (1, 'press'), (1, 'pollard'), (1, 'poignant'), (1, 'pleasing'), (1, 'picture'), (1, 'photography'), (1, 'peter'), (1, 'perhaps'), (1, 'performance'), (1, 'ought'), (1, 'opinion'), (1, 'opening'), (1, 'only'), (1, 'ones'), (1, 'olympian'), (1, 'offer'), (1, 'nusair'), (1, 'nov'), (1, 'normal'), (1, 'nonetheless'), (1, 'nominated'), (1, 'no'), (1, 'nicely'), (1, 'new'), (1, 'nearly'), (1, 'nation'), (1, 'move'), (1, 'motion'), (1, 'most'), (1, 'more'), (1, 'monitor'), (1, 'moment'), (1, 'minutes'), (1, 'minds'), (1, 'mike'), (1, 'message'), (1, 'mesmerizing'), (1, 'memorable'), (1, 'meant'), (1, 'may'), (1, 'master'), (1, 'massie'), (1, 'mar'), (1, 'mantel'), (1, 'man'), (1, 'make'), (1, 'magazine'), (1, 'machine'), (1, 'los'), (1, 'look'), (1, 'likely'), (1, 'like'), (1, 'life'), (1, 'legend'), (1, 'last'), (1, 'language'), (1, 'laced'), (1, 'killers'), (1, 'kauffmann'), (1, 'justifiably'), (1, 'jul'), (1, 'judgment'), (1, 'john'), (1, 'jesus'), (1, 'jan'), (1, 'jack'), (1, 'isn'), (1, 'invested'), (1, 'international'), (1, 'intense'), (1, 'insanity'), (1, 'inquirer'), (1, 'innocent'), (1, 'injustice'), (1, 'indoctrination'), (1, 'indication'), (1, 'images'), (1, 'identity'), (1, 'ideas'), (1, 'idea'), (1, 'iconic'), (1, 'hurlburt'), (1, 'humour'), (1, 'hollywood'), (1, 'hitting'), (1, 'hits'), (1, 'hilary'), (1, 'hearts'), (1, 'he'), (1, 'harsh'), (1, 'hard'), (1, 'had'), (1, 'gross'), (1, 'gone'), (1, 'get'), (1, 'genuinely'), (1, 'genius'), (1, 'garner'), (1, 'gannett'), (1, 'further'), (1, 'fundamental'), (1, 'frame'), (1, 'foremost'), (1, 'florida'), (1, 'flickdirect'), (1, 'first'), (1, 'feb'), (1, 'familiar'), (1, 'falls'), (1, 'extraordinary'), (1, 'explain'), (1, 'exercise'), (1, 'except'), (1, 'excellent'), (1, 'every'), (1, 'ermey'), (1, 'enough'), (1, 'electrifying'), (1, 'ed'), (1, 'ecstasy'), (1, 'easy'), (1, 'don'), (1, 'doesn'), (1, 'does'), (1, 'director'), (1, 'directed'), (1, 'devote'), (1, 'desmond'), (1, 'death'), (1, 'dark'), (1, 'daily'), (1, 'created'), (1, 'could'), (1, 'contribute'), (1, 'contrasting'), (1, 'considerable'), (1, 'commentary'), (1, 'comes'), (1, 'co'), (1, 'clinical'), (1, 'classics'), (1, 'cinematic'), (1, 'cinema'), (1, 'christian'), (1, 'challenging'), (1, 'caught'), (1, 'cathy'), (1, 'carnage'), (1, 'callous'), (1, 'by'), (1, 'burke'), (1, 'burden'), (1, 'brimming'), (1, 'brayton'), (1, 'born'), (1, 'blank'), (1, 'benson'), (1, 'ben'), (1, 'believable'), (1, 'become'), (1, 'awaited'), (1, 'audience'), (1, 'artists'), (1, 'artful'), (1, 'apr'), (1, 'antagony'), (1, 'angeles'), (1, 'andrew'), (1, 'analysis'), (1, 'amp'), (1, 'amount'), (1, 'americans'), (1, 'alone'), (1, 'allison'), (1, 'aiming'), (1, 'adrian'), (1, 'action'), (1, 'achievement'), (1, '45'), (1, '31'), (1, '25'), (1, '22'), (1, '2017'), (1, '2016'), (1, '2014'), (1, '2'), (1, '1'), (1, '0'), (1, '')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finally, explore what you can learn from this dictionary. Try: \r\n",
    "# A. Sorting your dictionary using our prebuilt method\r\n",
    "# B. Printing the top five most frequent words from your data\r\n",
    "# C. Querying for certain key words and printing their frequency\r\n",
    "# D. Comparing the relative frequency of words of interest"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "384b16392d5df87b45fa68fd804fdd570b449e149e441c1270eb35604a8982f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}