{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise Seven Starter: Textual Analysis\r\n",
    "\r\n",
    "In this exercise, I will not be providing the subheadings. Work from our code examples and the textbooks to construct a well-documented notebook that provides a model for initial textual analysis of a multi-document corpus.\r\n",
    "\r\n",
    "Your workflow should:\r\n",
    "- 1 Import at least three documents you would like to compare (from text files, or using another format for a challenge.)\r\n",
    "- 2 Preprocess the text and create a tokenized corpus from the text of the imported documents.\r\n",
    "- 3 Create a document term matrix to enable comparative textual analysis across the full set of documents\r\n",
    "- 4 Chart at least one comparison between the documents, using word frequency to map the text\r\n",
    "- 5 Calculate the Euclidean distance between the documents, using two key words as the point of comparison \r\n",
    "\r\n",
    "As a bonus challenge, consider trying one of the other types of distance modeling described in the text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step One\r\n",
    "Since it is nearing Halloween, I decided to analyze three classic horror novels:  <i>Frankenstein</i> by Mary Shelley, <i>Dracula</i> by Bram Stoker, and <i>Dr. Jekyll and Mr. Hyde</i> by Robert Louis Stevenson.  All three were available on Project Gutenberg.  I scraped the text from the site and saved them as txt files in VSC, using the author's last name as the file name.  I then imported all three files into this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# 1\r\n",
    "import nltk\r\n",
    "import nltk.tokenize\r\n",
    "\r\n",
    "# download the most recent punkt package\r\n",
    "nltk.download('punkt', quiet=True)\r\n",
    "\r\n",
    "corpus = [\"shelley.txt\",\"stoker.txt\",\"stevenson.txt\"]\r\n",
    "titles = [\"Frankenstein\", \"Dracula\", \"Jekyll And Hyde\"]\r\n",
    "documents = []\r\n",
    "for url in corpus:\r\n",
    "    f = open(url, encoding='utf-8')\r\n",
    "    text = f.read()\r\n",
    "    documents.append(text)\r\n",
    "print(documents[1][0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Project Gutenberg eBook of Dracula, by Bram Stoker\n",
      "\n",
      "This eBook is for the use of anyone anywher\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step Two\r\n",
    "The following three cells preprocessed the text and created a tokenized corpus from the text of the imported documents.  The first cell imported re and dealt with punctuation.  The second converted the text to lower case and tokenized the language.  The third cell tested the tokens."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 2\r\n",
    "import re\r\n",
    "\r\n",
    "\r\n",
    "PUNCT_RE = re.compile(r'[^\\w\\s]+$')\r\n",
    "\r\n",
    "\r\n",
    "def is_punct(string):\r\n",
    "    \"\"\"Check if STRING is a punctuation marker or a sequence of\r\n",
    "       punctuation markers.\r\n",
    "    \"\"\"\r\n",
    "    return PUNCT_RE.match(string) is not None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 2\r\n",
    "def preprocess_text(text, language, lowercase=True):\r\n",
    "    \"\"\"Preprocess a text.\r\n",
    "\r\n",
    "    Perform a text preprocessing procedure, which transforms a string\r\n",
    "    object into a list of word tokens without punctuation markers.\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    if lowercase:\r\n",
    "        text = text.lower()\r\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=language)\r\n",
    "    tokens = [token for token in tokens if not is_punct(token)]\r\n",
    "    return tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 2\r\n",
    "tokenized = []\r\n",
    "for text in documents:\r\n",
    "    tokenized.append(preprocess_text(text, \"english\"))\r\n",
    "\r\n",
    "print(tokenized[0][11])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3\r\n",
    "This next cell created a document term matrix to enable comparative textual analysis across the full set of documents.  It converted all the tokenized words into a searchable vocabulary.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 3\r\n",
    "def extract_vocabulary(tokenized_corpus, min_count=1, max_count=float('inf')):\r\n",
    "    \"\"\"Extract a vocabulary from a tokenized corpus.\r\n",
    "\r\n",
    "    Arguments:\r\n",
    "        tokenized_corpus (list): a tokenized corpus represented, list\r\n",
    "            of lists of strings.\r\n",
    "        min_count (int, optional): the minimum occurrence count of a\r\n",
    "            vocabulary item in the corpus.\r\n",
    "        max_count (int, optional): the maximum occurrence count of a\r\n",
    "            vocabulary item in the corpus. Defaults to inf.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        list: An alphabetically ordered list of unique words in the\r\n",
    "            corpus, of which the frequencies adhere to the specified\r\n",
    "            minimum and maximum count.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> corpus = [['the', 'man', 'love', 'man', 'the'],\r\n",
    "                      ['the', 'love', 'book', 'wise', 'drama'],\r\n",
    "                      ['a', 'story', 'book', 'drama']]\r\n",
    "        >>> extract_vocabulary(corpus, min_count=2)\r\n",
    "        ['book', 'drama', 'love', 'man', 'the']\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    vocabulary = collections.Counter()\r\n",
    "    for document in tokenized_corpus:\r\n",
    "        vocabulary.update(document)\r\n",
    "    vocabulary = {word for word, count in vocabulary.items()\r\n",
    "                  if count >= min_count and count <= max_count}\r\n",
    "    return sorted(vocabulary)\r\n",
    "import collections\r\n",
    "vocabulary = extract_vocabulary(tokenized, min_count=2)\r\n",
    "print(vocabulary[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"'ad\", \"'all\", \"'are\", \"'arf-quid\", \"'armony\", \"'as-is\", \"'at\", \"'ave\", \"'bloofer\", \"'d\", \"'ead\", \"'elped\", \"'em\", \"'ere\", \"'here\", \"'igh\", \"'im\", \"'is\", \"'isself\", \"'ittin\", \"'ll\", \"'m\", \"'my\", \"'no\", \"'ole\", \"'ome\", \"'ouse\", \"'ow\", \"'owl\", \"'rats\", \"'re\", \"'s\", \"'that\", \"'ve\", \"'yes\", \"'you\", '1', '1.', '1.a', '1.b', '1.c', '1.d', '1.e', '1.e.1', '1.e.2', '1.e.3', '1.e.4', '1.e.5', '1.e.6', '1.e.7', '1.e.8', '1.e.9', '1.f', '1.f.1', '1.f.2', '1.f.3', '1.f.4', '1.f.5', '1.f.6', '10', '10:30', '11', '11th', '12', '12th', '13', '14', '15', '1500', '16', '17', '17—', '17—.', '18', '18th', '18—', '19', '2', '2.', '20', '2001', '2021', '21', '22', '23', '24', '25', '29', '3', '3.', '30', '31', '4', '4.', '5', '5,000', '5.', '50', '501', '596-1887.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step Four\r\n",
    "With the ability to compare words, the next two cells compared the instances of “monster” and “blood.”  I chose these words because all three works prominently feature monsters and a relatively high degree of blood related activity. \r\n",
    "\r\n",
    "I was surprised to find no use of the word monster in Stevenson’s work, as this is a story of a man becoming a monster.  I expected a high frequency of monster in Shelley’s work, as that is how Frankenstein’s creation is referred too.  Also, no surprise, <i>Dracula</i> had the most instances of blood.\r\n",
    "\r\n",
    "In the second cell for this step, I created a chart to visualize these frequencies.  \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 4\r\n",
    "def corpus2dtm(tokenized_corpus, vocabulary):\r\n",
    "    \"\"\"Transform a tokenized corpus into a document-term matrix.\r\n",
    "\r\n",
    "    Arguments:\r\n",
    "        tokenized_corpus (list): a tokenized corpus as a list of\r\n",
    "        lists of strings. vocabulary (list): An list of unique words.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        list: A list of lists representing the frequency of each term\r\n",
    "              in `vocabulary` for each document in the corpus.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> tokenized_corpus = [['the', 'man', 'man', 'smart'],\r\n",
    "                                ['a', 'the', 'man' 'love'],\r\n",
    "                                ['love', 'book', 'journey']]\r\n",
    "        >>> vocab = ['book', 'journey', 'man', 'love']\r\n",
    "        >>> corpus2dtm(tokenized_corpus, vocabulary)\r\n",
    "        [[0, 0, 2, 0], [0, 0, 1, 1], [1, 1, 0, 1]]\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    document_term_matrix = []\r\n",
    "    for document in tokenized_corpus:\r\n",
    "        document_counts = collections.Counter(document)\r\n",
    "        row = [document_counts[word] for word in vocabulary]\r\n",
    "        document_term_matrix.append(row)\r\n",
    "    return document_term_matrix\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "document_term_matrix = np.array(corpus2dtm(tokenized, vocabulary))\r\n",
    "monster = vocabulary.index('monster')\r\n",
    "blood = vocabulary.index('blood')\r\n",
    "\r\n",
    "monster_counts = document_term_matrix[:, monster]\r\n",
    "blood_counts = document_term_matrix[:, blood]\r\n",
    "print(\"Monster: \" + str(monster_counts))\r\n",
    "print(\"Blood: \" + str(blood_counts))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Monster: [30 23  0]\n",
      "Blood: [ 19 108   9]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# 4 visualization\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "x = np.arange(len(titles))\r\n",
    "width = 0.3\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "rects1 = ax.bar(x - width/2, monster_counts, width, label='Monster')\r\n",
    "rects2 = ax.bar(x + width/2, blood_counts, width, label='Blood')\r\n",
    "\r\n",
    "ax.set_ylabel('Word Count')\r\n",
    "ax.set_title('Frequency of Monster and Blood in Classic Horror Novels')\r\n",
    "ax.set_xticks(x)\r\n",
    "ax.set_xticklabels(titles)\r\n",
    "ax.legend()\r\n",
    "\r\n",
    "fig.tight_layout()\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5\r\n",
    "For this step, I calculated the Euclidean distance between the documents’ use of “monster” and “blood.”  First, I defined the terms for each array, again using the authors’ last names.  In the second cell, mathematical magic generated the Euclidean distance of the chosen terms between the three works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# 5\r\n",
    "shelley = np.array([monster_counts[0], blood_counts[0]])\r\n",
    "stoker = np.array([monster_counts[1], blood_counts[1]])\r\n",
    "stevenson = np.array([monster_counts[2], blood_counts[2]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 5'\r\n",
    "def euclidean_distance(a, b):\r\n",
    "    \"\"\"Compute the Euclidean distance between two vectors.\r\n",
    "\r\n",
    "    Note: ``numpy.linalg.norm(a - b)`` performs the\r\n",
    "    same calculation using a slightly faster method.\r\n",
    "\r\n",
    "    Arguments:\r\n",
    "        a (numpy.ndarray): a vector of floats or ints.\r\n",
    "        b (numpy.ndarray): a vector of floats or ints.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        float: The euclidean distance between vector a and b.\r\n",
    "\r\n",
    "    Examples:\r\n",
    "        >>> import numpy as np\r\n",
    "        >>> a = np.array([1, 4, 2, 8])\r\n",
    "        >>> b = np.array([2, 1, 4, 7])\r\n",
    "        >>> round(euclidean_distance(a, b), 2)\r\n",
    "        3.87\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\r\n",
    "\r\n",
    "shelleystoker = euclidean_distance(shelley, stoker)\r\n",
    "print(f'Shelley - Stoker: {shelleystoker:.2f}')\r\n",
    "\r\n",
    "shelleystevenson = euclidean_distance(shelley, stevenson)\r\n",
    "print(f'Shelley - Stevenson: {shelleystevenson:.2f}')\r\n",
    "\r\n",
    "stokerstevenson = euclidean_distance(stoker, stevenson)\r\n",
    "print(f'Stoker - Stevenson: {stokerstevenson:.2f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shelley - Stoker: 89.27\n",
      "Shelley - Stevenson: 31.62\n",
      "Stoker - Stevenson: 101.64\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "interpreter": {
   "hash": "0da26090e65dfd4cdfd0711879594308b8318542197956b2adc85226ab711834"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}